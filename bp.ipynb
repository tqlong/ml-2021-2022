{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bp.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "NjJHeEAQb2Iu",
        "LVica4Uxb5Vu",
        "MXa-1tHl-5Ms",
        "rR6tCFROb9oX",
        "S5t50kCacAI3",
        "HHz_bLwiQUpS",
        "uZdSPNC0Q5bZ",
        "-_uUfQ0iQ963",
        "t69qUIAQRBdW"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ef282f9dbd6b4d799f250ddc7dbe0192": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f38c5fa9c1b64b6ba3e62e5686e29e9a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1f4a3bb0465f40278a69860c7ece25ce",
              "IPY_MODEL_5a7b64ec05304d06a8a3847b90db8f1a",
              "IPY_MODEL_34656dfde386421081ec61579715bc61"
            ]
          }
        },
        "f38c5fa9c1b64b6ba3e62e5686e29e9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1f4a3bb0465f40278a69860c7ece25ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b8b8ee525afa4d2ca512ae57850b7701",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "epoch 199 step 38 train_loss 0.0300 train_acc 99.25% val_acc 98.15%: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c1bc864ba8ef4e2194b27ccaac4bd297"
          }
        },
        "5a7b64ec05304d06a8a3847b90db8f1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cf08886956ed404b8c62852f34c76b9b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 200,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 200,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_810c9952327c4809a273e8562d2db262"
          }
        },
        "34656dfde386421081ec61579715bc61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f018bdaf5c8148ccb66f003b4d66b1d3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 200/200 [00:57&lt;00:00,  3.39it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8310fa4894194d58aa2acf24560526fb"
          }
        },
        "b8b8ee525afa4d2ca512ae57850b7701": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c1bc864ba8ef4e2194b27ccaac4bd297": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cf08886956ed404b8c62852f34c76b9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "810c9952327c4809a273e8562d2db262": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f018bdaf5c8148ccb66f003b4d66b1d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8310fa4894194d58aa2acf24560526fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nu84Hh1I3hVY"
      },
      "source": [
        "import numpy as np\n",
        "import unittest\n",
        "import math"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-YpYDJ8ROdR"
      },
      "source": [
        "# The unit tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjJHeEAQb2Iu"
      },
      "source": [
        "## Tests for Fully connected layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EanSBThMPKMK"
      },
      "source": [
        "class TestFCMethods(unittest.TestCase):\n",
        "  def test_fc_init(self):\n",
        "    fc = FC(n_in=10, n_out=5, activation=\"sigmoid\")\n",
        "    self.assertEqual(fc.n_in, 10)\n",
        "    self.assertEqual(fc.n_out, 5)\n",
        "    self.assertEqual(fc.W.shape, (10,5))\n",
        "    self.assertEqual(fc.dW.shape, (10,5))\n",
        "    self.assertEqual(fc.activation, \"sigmoid\")\n",
        "\n",
        "  def test_fc_forward(self):\n",
        "    fc = FC(n_in=10, n_out=5, activation=\"sigmoid\")\n",
        "    x = np.zeros((3, 10), dtype=np.float32)\n",
        "    y = fc.forward(x)\n",
        "    error = np.sum(np.abs(y-np.ones((3,5))*0.5))\n",
        "    self.assertEqual(y.shape, (3, 5))\n",
        "    self.assertLess(error, 1e-6)\n",
        "\n",
        "  def test_fc_forward_identity(self):\n",
        "    fc = FC(n_in=10, n_out=5, activation=None)\n",
        "    x = np.zeros((3, 10), dtype=np.float32)\n",
        "    y = fc.forward(x)\n",
        "    error = np.sum(np.abs(y-np.zeros((3,5))))\n",
        "    self.assertEqual(y.shape, (3, 5))\n",
        "    self.assertLess(error, 1e-6)\n",
        "\n",
        "  def test_fc_backward_identity(self):\n",
        "    fc = FC(n_in=10, n_out=5, activation=None)\n",
        "    x = np.zeros((3, 10), dtype=np.float32)\n",
        "    y = fc.forward(x)\n",
        "    dx = fc.backward(np.ones_like(y))\n",
        "    ## exercise: should add test on error of dx here\n",
        "    self.assertEqual(dx.shape, x.shape)\n",
        "    self.assertEqual(fc.dW.shape, fc.W.shape)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVica4Uxb5Vu"
      },
      "source": [
        "## Tests for MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lI-o9ORkPOBv"
      },
      "source": [
        "class TestMLPMethods(unittest.TestCase):\n",
        "  def test_mlp_init(self):\n",
        "    model = MLP(n_in=10, hiddens=[5, 2])\n",
        "    layer0 = model.layers[0]\n",
        "    layer1 = model.layers[1]\n",
        "    self.assertEqual(model.n_in, 10)\n",
        "    self.assertEqual(model.hiddens, [5, 2])\n",
        "    self.assertEqual(layer0.n_in, 10)\n",
        "    self.assertEqual(layer0.n_out, 5)\n",
        "    self.assertEqual(layer1.n_in, 5)\n",
        "    self.assertEqual(layer1.n_out, 2)\n",
        "\n",
        "  def test_mlp_forward(self):\n",
        "    model = MLP(n_in=10, hiddens=[5, 2])\n",
        "    x = np.zeros((3, 10), dtype=np.float32)\n",
        "    y = model.forward(x)\n",
        "    self.assertEqual(y.shape, (3, 2))\n",
        "\n",
        "  def test_mlp_backward(self):\n",
        "    model = MLP(n_in=10, hiddens=[5, 2])\n",
        "    x = np.zeros((3, 10), dtype=np.float32)\n",
        "    y = model.forward(x)\n",
        "    dx = model.backward(np.ones_like(y))\n",
        "    self.assertEqual(dx.shape, x.shape)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXa-1tHl-5Ms"
      },
      "source": [
        "## Tests for ResBlock"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTZeMt_G-i77"
      },
      "source": [
        "class TestResBlockMethods(unittest.TestCase):\n",
        "  def test_res_init(self):\n",
        "    model = ResidualBlock(n_in=10, hiddens=[5, 6, 2])\n",
        "    fc = model.input_fc\n",
        "    layer0 = model.block.layers[0]\n",
        "    layer1 = model.block.layers[1]\n",
        "    skip = model.skip\n",
        "    self.assertEqual((fc.n_in, fc.n_out), (10,5))\n",
        "    self.assertEqual(model.block.n_in, 5)\n",
        "    self.assertEqual(model.block.hiddens, [6, 2])\n",
        "    self.assertEqual(layer0.n_in, 5)\n",
        "    self.assertEqual(layer0.n_out, 6)\n",
        "    self.assertEqual(layer1.n_in, 6)\n",
        "    self.assertEqual(layer1.n_out, 2)\n",
        "    self.assertEqual(skip.n_in, 5)\n",
        "    self.assertEqual(skip.n_out, 2)\n",
        "\n",
        "  def test_res_identity(self):\n",
        "    model = ResidualBlock(n_in=10, hiddens=[5, 6, 5])\n",
        "    fc = model.input_fc\n",
        "    layer0 = model.block.layers[0]\n",
        "    layer1 = model.block.layers[1]\n",
        "    skip = model.skip\n",
        "    self.assertEqual((fc.n_in, fc.n_out), (10,5))\n",
        "    self.assertEqual(model.block.n_in, 5)\n",
        "    self.assertEqual(model.block.hiddens, [6, 5])\n",
        "    self.assertEqual(layer0.n_in, 5)\n",
        "    self.assertEqual(layer0.n_out, 6)\n",
        "    self.assertEqual(layer1.n_in, 6)\n",
        "    self.assertEqual(layer1.n_out, 5)\n",
        "    self.assertIsNone(skip, None)\n",
        "\n",
        "  def test_res_forward(self):\n",
        "    model = ResidualBlock(n_in=10, hiddens=[5, 2])\n",
        "    x = np.zeros((3, 10), dtype=np.float32)\n",
        "    y = model.forward(x)\n",
        "    self.assertEqual(y.shape, (3, 2))\n",
        "\n",
        "  def test_res_backward(self):\n",
        "    model = ResidualBlock(n_in=10, hiddens=[5, 2])\n",
        "    x = np.zeros((3, 10), dtype=np.float32)\n",
        "    y = model.forward(x)\n",
        "    dx = model.backward(np.ones_like(y))\n",
        "    self.assertEqual(dx.shape, x.shape)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rR6tCFROb9oX"
      },
      "source": [
        "## Tests for Cross Entropy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SptdBfy-Vzeb"
      },
      "source": [
        "class TestCEMethods(unittest.TestCase):\n",
        "  def test_ce_forward(self):\n",
        "    ypred = np.zeros((10, 5))\n",
        "    ytrue = np.array([0,1,2,3,4,0,1,2,3,4], dtype=int)\n",
        "    ce = CrossEntropyLoss()\n",
        "    loss = ce.forward(ypred, ytrue)\n",
        "    self.assertAlmostEqual(loss, -10*math.log(1/5))\n",
        "\n",
        "  def test_ce_backward(self):\n",
        "    ypred = np.zeros((10, 5))\n",
        "    ytrue = np.array([0,1,2,3,4,0,1,2,3,4], dtype=int)\n",
        "    ce = CrossEntropyLoss()\n",
        "    loss = ce.forward(ypred, ytrue)\n",
        "    d_ypred = ce.backward()\n",
        "    desired = np.ones((10,5))*0.2\n",
        "    desired[range(10), ytrue] -= 1\n",
        "    error = np.sum(np.abs(d_ypred-desired))\n",
        "    self.assertAlmostEqual(error, 0)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5t50kCacAI3"
      },
      "source": [
        "## Tests for Stochastic Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6ofVdrLQOGN"
      },
      "source": [
        "class TestSGDMethods(unittest.TestCase):\n",
        "  def test_sgd_init(self):\n",
        "    model = MLP(n_in=10, hiddens=[5, 2])\n",
        "    sgd = SGDOptimizer(model, learning_rate=0.2, regularization=0.1)\n",
        "    param = sgd.parameters()\n",
        "    grad = sgd.grads()\n",
        "    \n",
        "    for p, g in zip(param, grad):\n",
        "      self.assertEqual(p.shape, g.shape)\n",
        "    self.assertEqual(sgd.learning_rate, 0.2)\n",
        "    self.assertEqual(sgd.regularization, 0.1)\n",
        "\n",
        "\n",
        "  def test_sgd_zero_grad(self):\n",
        "    model = MLP(n_in=10, hiddens=[5, 2])\n",
        "    sgd = SGDOptimizer(model, learning_rate=0.2)\n",
        "    sgd.zero_grad()\n",
        "\n",
        "    for g in sgd.grads():\n",
        "      self.assertAlmostEqual(np.sum(np.abs(g)), 0)\n",
        "\n",
        "  def test_sgd_step(self):\n",
        "    model = MLP(n_in=10, hiddens=[5, 2])\n",
        "    sgd = SGDOptimizer(model, learning_rate=0.2)\n",
        "    loss_func = CrossEntropyLoss()\n",
        "    \n",
        "    x = np.zeros((3, 10), dtype=np.float32)\n",
        "    ytrue = np.array([0,1,0], dtype=int)\n",
        "\n",
        "    ypred = model.forward(x)\n",
        "    loss = loss_func.forward(ypred, ytrue)\n",
        "\n",
        "    sgd.zero_grad()\n",
        "    dout = loss_func.backward()\n",
        "    dx = model.backward(dout)\n",
        "    sgd.step()\n",
        "\n",
        "  def test_sgd_n_step(self):\n",
        "    model = MLP(n_in=10, hiddens=[5, 2])\n",
        "    sgd = SGDOptimizer(model, learning_rate=0.02)\n",
        "    loss_func = CrossEntropyLoss()\n",
        "    n_step = 10\n",
        "    \n",
        "    x = np.zeros((3, 10), dtype=np.float32)\n",
        "    ytrue = np.array([0,1,0], dtype=int)\n",
        "\n",
        "    print()\n",
        "    for step in range(n_step):\n",
        "      model.train()\n",
        "      ypred = model.forward(x)\n",
        "      loss = loss_func.forward(ypred, ytrue)\n",
        "\n",
        "      print(f\"step {step} {loss:.4f}\")\n",
        "      if step > 0:\n",
        "        self.assertLess(loss, old_loss) ## SGD step reduces loss function\n",
        "      old_loss = loss\n",
        "\n",
        "      sgd.zero_grad()\n",
        "      dout = loss_func.backward()\n",
        "      dx = model.backward(dout)\n",
        "      sgd.step()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfm1j_Ui8Z9o"
      },
      "source": [
        "## Tests for Dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bbJmH-n8b6D"
      },
      "source": [
        "class TestDropoutMethods(unittest.TestCase):\n",
        "  def test_dropout_init(self):\n",
        "    do = Dropout(p=0.2)\n",
        "    self.assertEqual(do.p, 0.2)\n",
        "    self.assertEqual(do.parameters(), [])\n",
        "    self.assertEqual(do.grads(), [])\n",
        "\n",
        "  def test_dropout_forward(self):\n",
        "    do = Dropout(p=0.30)\n",
        "    np.random.seed(42)\n",
        "    x = np.ones((10, 10))\n",
        "    y = do.forward(x)\n",
        "    count_zero = np.sum(y==0)\n",
        "    self.assertEqual(count_zero, 34)\n",
        "\n",
        "  def test_dropout_back(self):\n",
        "    do = Dropout(p=0.30)\n",
        "    np.random.seed(42)\n",
        "    x = np.ones((10, 10))*2\n",
        "    y = do.forward(x)\n",
        "    dx = do.backward(np.ones_like(y))\n",
        "    count_zero = np.sum(dx==0)\n",
        "    self.assertEqual(count_zero, 34)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iM6K_LZbdqoO"
      },
      "source": [
        "# FC Layer, MLP, ResNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHz_bLwiQUpS"
      },
      "source": [
        "\n",
        "## Fully connected *layer*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJOxwpwDAnvm"
      },
      "source": [
        "class FC:\n",
        "  def __init__(self, n_in, n_out, activation=None):\n",
        "    self.n_in = n_in\n",
        "    self.n_out = n_out\n",
        "    self.activation = activation\n",
        "    # self.W = np.zeros(shape=(n_in, n_out))\n",
        "    std = math.sqrt(2) if activation == \"relu\" else 1.0\n",
        "    self.W = np.random.normal(scale=1.0/math.sqrt(n_in), size=(n_in, n_out))\n",
        "    self.dW = np.zeros(shape=(n_in, n_out))\n",
        "\n",
        "  @staticmethod\n",
        "  def stable_sigmoid(x):\n",
        "    z = np.zeros_like(x)\n",
        "    z[x >= 0] = 1 / ( 1+np.exp(-x[x >= 0]) )\n",
        "    z[x < 0] = np.exp(x[x < 0])\n",
        "    z[x < 0] = z[x < 0] / ( 1+z[x < 0] )\n",
        "    return z\n",
        "\n",
        "  def __activation(self, a):\n",
        "    if self.activation is None:\n",
        "      f = a.copy() # N x n_out\n",
        "    elif self.activation == \"sigmoid\":\n",
        "      f = self.stable_sigmoid(a) # 1.0/(1+np.exp(-self.a))\n",
        "    elif self.activation == \"relu\":\n",
        "      f = a.copy()\n",
        "      f[a < 0] = 0\n",
        "    else:\n",
        "      raise NotImplementedError(f\"NotImplementedError FC.forward activation={self.activation}\")\n",
        "    return f\n",
        "\n",
        "  def __dactivation(self, df, f, a):\n",
        "    if self.activation is None:\n",
        "      da = df.copy() # N x n_out\n",
        "    elif self.activation == \"sigmoid\":\n",
        "      da = f*(1-f)*df # N x n_out\n",
        "    elif self.activation == \"relu\":\n",
        "      da = df.copy()\n",
        "      da[a < 0] = 0\n",
        "    else:\n",
        "      raise NotImplementedError(f\"NotImplementedError FC.backward activation={self.activation}\")\n",
        "    return da\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    ## x: N x n_in\n",
        "    ## save computation for backward phase\n",
        "    self.x = x.copy()\n",
        "    self.a = np.matmul(x, self.W) # N x n_out\n",
        "    self.f = self.__activation(self.a)\n",
        "    return self.f\n",
        "\n",
        "  def backward(self, df):\n",
        "    ## df: N x n_out\n",
        "    ## use pre-compute self.x, self.a and self.f to compute dx and dW\n",
        "    da = self.__dactivation(df, self.f, self.a)\n",
        "    self.dW = np.einsum('ij,ik->jk', self.x, da) # n_in x n_out\n",
        "    self.dx = np.matmul(da, self.W.T) # N x n_in\n",
        "    self.df = df\n",
        "    self.da = da\n",
        "    return self.dx\n",
        "\n",
        "  def parameters(self):\n",
        "    return [self.W]\n",
        "\n",
        "  def grads(self):\n",
        "    return [self.dW]\n",
        "\n",
        "  def train(self):\n",
        "    pass\n",
        "  \n",
        "  def eval(self):\n",
        "    pass"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZdSPNC0Q5bZ"
      },
      "source": [
        "## Multilayer Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGNRJ3Sp7eUG"
      },
      "source": [
        "class MLP:\n",
        "  def __init__(self, n_in, hiddens, activation=\"sigmoid\", last_layer_linear=True):\n",
        "    self.n_in = n_in\n",
        "    self.hiddens = hiddens\n",
        "    self.layers = [\n",
        "                   # use sigmoid activation for hidden layer\n",
        "                   # use linear activation for output layer\n",
        "                   FC(n_in=hiddens[i-1] if i > 0 else n_in,\n",
        "                      n_out=hiddens[i],\n",
        "                      activation=activation if (i < len(hiddens)-1) or (not last_layer_linear) else None)\n",
        "                   for i in range(len(hiddens))\n",
        "                   ]\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = x\n",
        "    for layer in self.layers:\n",
        "      out = layer.forward(out)\n",
        "    return out\n",
        "\n",
        "  def backward(self, dout):\n",
        "    for layer in self.layers[::-1]:\n",
        "      dout = layer.backward(dout)\n",
        "    return dout\n",
        "\n",
        "  def parameters(self):\n",
        "    return sum([layer.parameters() for layer in self.layers], [])\n",
        "\n",
        "  def grads(self):\n",
        "    return sum([layer.grads() for layer in self.layers], [])\n",
        "\n",
        "  def train(self):\n",
        "    for layer in self.layers:\n",
        "      layer.train()\n",
        "\n",
        "  def eval(self):\n",
        "    for layer in self.layers:\n",
        "      layer.eval()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tzBj0uq8h4m"
      },
      "source": [
        "## Residual Block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61aJxSwe8nOu"
      },
      "source": [
        "class ResidualBlock:\n",
        "  def __init__(self, n_in, hiddens, activation=\"sigmoid\", last_layer_linear=False, dropout=-1.0):\n",
        "    ## initialize layers\n",
        "    n_out = hiddens[-1]\n",
        "    self.input_fc = FC(n_in, hiddens[0], activation=activation)\n",
        "    self.block = MLP(n_in=hiddens[0], hiddens=hiddens[1:], activation=activation, last_layer_linear=last_layer_linear)\n",
        "    self.skip = FC(n_in=hiddens[0], n_out=n_out, activation=activation) if hiddens[0] != n_out else None\n",
        "    self.dropout = Dropout(p=dropout) if dropout > 0 else None\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.input_fc.forward(x)\n",
        "    block_out = self.block.forward(x)\n",
        "    skip_out = self.skip.forward(x) if self.skip is not None else x\n",
        "    out = block_out + skip_out\n",
        "    out = self.dropout.forward(out) if self.dropout is not None else out\n",
        "    return out\n",
        "\n",
        "  def backward(self, dout):\n",
        "    dout = self.dropout.backward(dout) if self.dropout is not None else dout\n",
        "    d_block_in = self.block.backward(dout)\n",
        "    d_skip_in  = self.skip.backward(dout) if self.skip is not None else dout\n",
        "    dx = d_block_in + d_skip_in\n",
        "    dx = self.input_fc.backward(dx)\n",
        "    return dx\n",
        "\n",
        "  def parameters(self):\n",
        "    return self.input_fc.parameters() + self.block.parameters() + (self.skip.parameters() if self.skip is not None else [])\n",
        "\n",
        "  def grads(self):\n",
        "    return self.input_fc.grads() + self.block.grads() + (self.skip.grads() if self.skip is not None else [])\n",
        "\n",
        "  def train(self):\n",
        "    self.input_fc.train()\n",
        "    self.block.train()\n",
        "    if self.skip is not None:\n",
        "      self.skip.train()\n",
        "    if self.dropout is not None:\n",
        "      self.dropout.train()\n",
        "\n",
        "  def eval(self):\n",
        "    self.input_fc.eval()\n",
        "    self.block.eval()\n",
        "    if self.skip is not None:\n",
        "      self.skip.eval()\n",
        "    if self.dropout is not None:\n",
        "      self.dropout.eval()\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsAnUUScL2C9"
      },
      "source": [
        "## Residual Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qWdGLk0CS2J"
      },
      "source": [
        "class ResNet:\n",
        "  def __init__(self, n_in, blocks_hiddens, n_out, activation=\"sigmoid\", dropout=None):\n",
        "    self.n_in = n_in\n",
        "    self.blocks_hiddens = blocks_hiddens\n",
        "    self.n_out = n_out\n",
        "\n",
        "    self.blocks = [\n",
        "                   ResidualBlock(\n",
        "                       n_in=blocks_hiddens[i-1][-1] if i > 0 else n_in,\n",
        "                       hiddens = blocks_hiddens[i],\n",
        "                       activation=activation,\n",
        "                       last_layer_linear=False,\n",
        "                       dropout=-1 if dropout is None else dropout[i]\n",
        "                       )\n",
        "                   for i in range(len(blocks_hiddens))\n",
        "                   ]\n",
        "    self.fc = FC(n_in=blocks_hiddens[-1][-1], n_out=n_out)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = x\n",
        "    for block in self.blocks:\n",
        "      out = block.forward(out)\n",
        "    out = self.fc.forward(out)\n",
        "    return out\n",
        "\n",
        "  def backward(self, dout):\n",
        "    dout = self.fc.backward(dout)\n",
        "    for block in self.blocks[::-1]:\n",
        "      dout = block.backward(dout)\n",
        "    return dout\n",
        "\n",
        "  def parameters(self):\n",
        "    return sum([block.parameters() for block in self.blocks], []) + self.fc.parameters()\n",
        "\n",
        "  def grads(self):\n",
        "    return sum([block.grads() for block in self.blocks], []) + self.fc.grads()\n",
        "\n",
        "  def train(self):\n",
        "    for layer in self.blocks+[self.fc]:\n",
        "      layer.train()\n",
        "\n",
        "  def eval(self):\n",
        "    for layer in self.blocks+[self.fc]:\n",
        "      layer.eval()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRt5TIlU8yUd"
      },
      "source": [
        "## Dropout layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4K0JEeK80cn"
      },
      "source": [
        "class Dropout:\n",
        "  def __init__(self, p):\n",
        "    self.p = p\n",
        "    self.is_train = True\n",
        "\n",
        "  def parameters(self):\n",
        "    return []\n",
        "\n",
        "  def grads(self):\n",
        "    return []\n",
        "\n",
        "  def forward(self, x):\n",
        "    if self.is_train:\n",
        "      self.mask = np.random.rand(*x.shape) < self.p\n",
        "      self.x = x\n",
        "      y = x.copy()\n",
        "      y[self.mask] = 0\n",
        "    else:\n",
        "      y = x * (1-self.p)\n",
        "    return y\n",
        "\n",
        "  def backward(self, dy):\n",
        "    dx = dy.copy()\n",
        "    dx[self.mask] = 0\n",
        "    return dx\n",
        "\n",
        "  def train(self):\n",
        "    self.is_train = True\n",
        "\n",
        "  def eval(self):\n",
        "    self.is_train = False\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_uUfQ0iQ963"
      },
      "source": [
        "# Cross Entropy Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bY_-xnnAbwoC"
      },
      "source": [
        "class CrossEntropyLoss:\n",
        "  @staticmethod\n",
        "  def stable_softmax(X):\n",
        "    exps = np.exp(X - np.max(X, axis=1, keepdims=True))\n",
        "    return exps / np.sum(exps, axis=1, keepdims=True)\n",
        "\n",
        "  def forward(self, ypred, ytrue):\n",
        "    ## ypred: N x n_out (logit values)\n",
        "    ## ytrue: N (class label: int value in 0-->n_out-1)\n",
        "    ## should return - sum_i sum_c y_ic \\log mu_ic\n",
        "    n, n_out = ypred.shape\n",
        "    self.ypred = ypred\n",
        "    self.ytrue = ytrue\n",
        "    self.mu = self.stable_softmax(ypred)\n",
        "    loss = np.sum(-np.log(self.mu[range(n), ytrue]))\n",
        "    return loss\n",
        "\n",
        "  def backward(self):\n",
        "    ## should return d_ypred, derivative of loss on ypred\n",
        "    ## d_ypred = mu - y (one-hot encoding of ytrue)\n",
        "    n, n_out = self.ypred.shape\n",
        "    d_ypred = self.mu.copy()\n",
        "    d_ypred[range(n), self.ytrue] -= 1\n",
        "    return d_ypred"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t69qUIAQRBdW"
      },
      "source": [
        "# Stochastic Gradient Descent optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCYdXS3Kb0Py"
      },
      "source": [
        "import math\n",
        "class SGDOptimizer:\n",
        "  def __init__(self, model, learning_rate, regularization=0.0):\n",
        "    self.model = model\n",
        "    self.learning_rate = learning_rate\n",
        "    self.regularization = regularization\n",
        "    self.current_step = 0\n",
        "\n",
        "  def parameters(self):\n",
        "    return self.model.parameters()\n",
        "\n",
        "  def grads(self):\n",
        "    return self.model.grads()\n",
        "\n",
        "  def zero_grad(self):\n",
        "    for g in self.grads():\n",
        "      g.fill(0)\n",
        "\n",
        "  def step(self):\n",
        "    ## input is the derivative of loss function on the output of the model\n",
        "    ## dW has been computed by backward functions\n",
        "    ## perform a gradient step W = W - 1/sqrt(t) lambda dW\n",
        "    ## the learning rate is reduced over time for convergence\n",
        "    self.current_step += 1\n",
        "    for p, g in zip(self.parameters(), self.grads()):\n",
        "      g = self.regularization*p + g\n",
        "      g = np.clip(g, -1, 1)\n",
        "      p -= 1.0 / math.sqrt(self.current_step)*self.learning_rate*g\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eCyi0WfRF24"
      },
      "source": [
        "# Run the unit tests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "af8ka5CP7IDW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e76fb4f0-c351-4ce8-cf93-1ee7c50b3783"
      },
      "source": [
        "unittest.main(argv=[''], verbosity=2, exit=False)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "test_ce_backward (__main__.TestCEMethods) ... ok\n",
            "test_ce_forward (__main__.TestCEMethods) ... ok\n",
            "test_dropout_back (__main__.TestDropoutMethods) ... ok\n",
            "test_dropout_forward (__main__.TestDropoutMethods) ... ok\n",
            "test_dropout_init (__main__.TestDropoutMethods) ... ok\n",
            "test_fc_backward_identity (__main__.TestFCMethods) ... ok\n",
            "test_fc_forward (__main__.TestFCMethods) ... ok\n",
            "test_fc_forward_identity (__main__.TestFCMethods) ... ok\n",
            "test_fc_init (__main__.TestFCMethods) ... ok\n",
            "test_mlp_backward (__main__.TestMLPMethods) ... ok\n",
            "test_mlp_forward (__main__.TestMLPMethods) ... ok\n",
            "test_mlp_init (__main__.TestMLPMethods) ... ok\n",
            "test_res_backward (__main__.TestResBlockMethods) ... ok\n",
            "test_res_forward (__main__.TestResBlockMethods) ... ok\n",
            "test_res_identity (__main__.TestResBlockMethods) ... ok\n",
            "test_res_init (__main__.TestResBlockMethods) ... ok\n",
            "test_sgd_init (__main__.TestSGDMethods) ... ok\n",
            "test_sgd_n_step (__main__.TestSGDMethods) ... ok\n",
            "test_sgd_step (__main__.TestSGDMethods) ... ok\n",
            "test_sgd_zero_grad (__main__.TestSGDMethods) ... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "step 0 1.9250\n",
            "step 1 1.9240\n",
            "step 2 1.9234\n",
            "step 3 1.9229\n",
            "step 4 1.9225\n",
            "step 5 1.9221\n",
            "step 6 1.9218\n",
            "step 7 1.9215\n",
            "step 8 1.9212\n",
            "step 9 1.9210\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ok\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 20 tests in 0.104s\n",
            "\n",
            "OK\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<unittest.main.TestProgram at 0x7fc6edd21690>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4rVeDzbouZk"
      },
      "source": [
        "# A training and evaluation example\n",
        "MLP network and ResNet (more layers)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuiQX3If46hE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518,
          "referenced_widgets": [
            "ef282f9dbd6b4d799f250ddc7dbe0192",
            "f38c5fa9c1b64b6ba3e62e5686e29e9a",
            "1f4a3bb0465f40278a69860c7ece25ce",
            "5a7b64ec05304d06a8a3847b90db8f1a",
            "34656dfde386421081ec61579715bc61",
            "b8b8ee525afa4d2ca512ae57850b7701",
            "c1bc864ba8ef4e2194b27ccaac4bd297",
            "cf08886956ed404b8c62852f34c76b9b",
            "810c9952327c4809a273e8562d2db262",
            "f018bdaf5c8148ccb66f003b4d66b1d3",
            "8310fa4894194d58aa2acf24560526fb"
          ]
        },
        "outputId": "5d4d5ad2-4728-44a7-db17-00a34e1e1fe1"
      },
      "source": [
        "import sklearn\n",
        "from sklearn import datasets\n",
        "from sklearn import metrics\n",
        "from sklearn import model_selection\n",
        "from sklearn import preprocessing\n",
        "from tqdm.notebook import tqdm_notebook as tqdm\n",
        "\n",
        "def prepare_data():\n",
        "  X, y = datasets.load_digits(return_X_y=True)\n",
        "  X, Xtest, y, ytest = model_selection.train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "  transform = preprocessing.MinMaxScaler()\n",
        "  X = transform.fit_transform(X)\n",
        "  Xtest = transform.transform(Xtest)\n",
        "  return X, Xtest, y, ytest\n",
        "\n",
        "def prepare_trainer(model):\n",
        "  sgd = SGDOptimizer(model, learning_rate=0.1, regularization=0.03)\n",
        "  loss_func = CrossEntropyLoss()\n",
        "  return sgd, loss_func\n",
        "\n",
        "def prepare_data_loader(X, y, batch_size):\n",
        "  n = X.shape[0]\n",
        "  permutation = np.random.permutation(n)\n",
        "  for i in range(0, n, batch_size):\n",
        "    j = i+batch_size if i+batch_size <= n else n\n",
        "    batch_x = X[permutation[i:j]]\n",
        "    batch_y = y[permutation[i:j]]\n",
        "    yield batch_x, batch_y\n",
        "\n",
        "def get_model(n_in):\n",
        "  np.random.seed(101)\n",
        "  # model = MLP(n_in=n_in, hiddens=[128, 64, 10], activation=\"relu\")\n",
        "  # model = ResNet(n_in=n_in, blocks_hiddens=[[128,64,128]], n_out=10, activation=\"sigmoid\")\n",
        "  model = ResNet(\n",
        "      n_in=n_in,\n",
        "      blocks_hiddens=[[128,64,128], [64,32,64], [32,16,32], [16,8,16]],\n",
        "      n_out=10,\n",
        "      activation=\"relu\",\n",
        "      dropout=[0.2,0.2,0.2,0.2])\n",
        "  # model = ResNet(n_in=n_in, blocks_hiddens=[[128,16,128], [64,8,64], [32,4,32], [16,2,16]], n_out=10, activation=\"relu\")\n",
        "  return model\n",
        "\n",
        "def main():\n",
        "  X, Xtest, y, ytest = prepare_data()\n",
        "  n_in, n_out = X.shape[1], 10\n",
        "  n_epoch = 200\n",
        "  batch_size = 32\n",
        "\n",
        "  model = get_model(n_in)\n",
        "  sgd, loss_func = prepare_trainer(model)\n",
        "\n",
        "  pbar = tqdm(range(n_epoch))\n",
        "  val_acc = 0\n",
        "  for epoch in pbar:\n",
        "    data_loader = prepare_data_loader(X, y, batch_size)\n",
        "    step = 0\n",
        "    total_loss, total_correct = 0, 0\n",
        "    total_sample = 0\n",
        "\n",
        "    model.train()\n",
        "    for batch_x, batch_y in data_loader:\n",
        "      ## forward pass\n",
        "      batch_yp = model.forward(batch_x)\n",
        "      loss = loss_func.forward(batch_yp, batch_y)\n",
        "\n",
        "      ## backward pass and an optimization step\n",
        "      sgd.zero_grad()\n",
        "      dout = loss_func.backward()\n",
        "      dx = model.backward(dout)\n",
        "      sgd.step()\n",
        "\n",
        "      ## log training progress\n",
        "      step += 1\n",
        "      total_loss += loss\n",
        "      total_correct += np.sum(np.argmax(batch_yp, axis=1) == batch_y)\n",
        "      total_sample += len(batch_y)\n",
        "      pbar.set_description(f\"epoch {epoch} step {step} train_loss {total_loss/total_sample:.4f} train_acc {total_correct/total_sample*100:.2f}% val_acc {val_acc*100:.2f}%\")\n",
        "    \n",
        "    model.eval()\n",
        "    val_acc = np.sum(np.argmax(model.forward(Xtest), axis=1) == ytest) / len(ytest)\n",
        "\n",
        "  ypred = np.argmax(model.forward(Xtest), axis=1)\n",
        "  print(metrics.classification_report(ytest, ypred))\n",
        "  print(metrics.confusion_matrix(ytest, ypred))\n",
        "\n",
        "main()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef282f9dbd6b4d799f250ddc7dbe0192",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99        55\n",
            "           1       0.98      0.98      0.98        55\n",
            "           2       0.98      1.00      0.99        52\n",
            "           3       1.00      0.96      0.98        56\n",
            "           4       0.98      1.00      0.99        64\n",
            "           5       0.97      0.97      0.97        73\n",
            "           6       0.97      0.98      0.97        57\n",
            "           7       0.97      0.98      0.98        62\n",
            "           8       0.98      0.94      0.96        52\n",
            "           9       0.99      0.97      0.98        68\n",
            "\n",
            "    accuracy                           0.98       594\n",
            "   macro avg       0.98      0.98      0.98       594\n",
            "weighted avg       0.98      0.98      0.98       594\n",
            "\n",
            "[[55  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 54  0  0  0  0  0  1  0  0]\n",
            " [ 0  0 52  0  0  0  0  0  0  0]\n",
            " [ 0  0  1 54  0  1  0  0  0  0]\n",
            " [ 0  0  0  0 64  0  0  0  0  0]\n",
            " [ 0  0  0  0  1 71  1  0  0  0]\n",
            " [ 1  0  0  0  0  0 56  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 61  0  1]\n",
            " [ 0  1  0  0  0  1  1  0 49  0]\n",
            " [ 0  0  0  0  0  0  0  1  1 66]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtO6A5oy83SD"
      },
      "source": [
        ""
      ],
      "execution_count": 16,
      "outputs": []
    }
  ]
}